/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

/**
  XML grammar suitable for syntax coloring. Currently it
  returns: tag names, strings, ... and comments.

  <h3>Suggestion to JavaCC developers</h3>
  JavaCC [Token Manager] would be improved in following areas:

  <li>TOKENMGR_BEGIN/END instead of TOKEN_MGR_DECLS.
  <ul>
    <li>It would allow TokenManager be a subclass.
    <li>It would lead to code reuse/space save.
    <li>It would be helpfull it a application uses more than one JavaCC generated analyzers.
  </ul>


  <li>Intoduction of lookahead (LA as ANLTR calls it is better than long LOOKAHEAD)
  at lexical rules.

  <li> Allow to return same token from more states. 
  Construct that reclassifies returned token. E.g. It would generate 
  <pre>
  { matchedToken.kind = newKind; }
  </pre>
  Or allow non-unique token names. E.g. 
  <SOFT_ERR: "?"> in default state and <SOFT_ERR: "--"> in comment state.

  <li>ASCIICharStream etc. should be declared as CharStream implementations

  <p>NOTE: Remove UCode_CharStream.java after javacc this source.

  @author Petr Kuzel
*/

options {
//      USER_CHAR_STREAM = true;
    UNICODE_INPUT = true;  // generate unicode aware code
    BUILD_PARSER = false;
    STATIC = false;
    LOOKAHEAD = 1;
}


PARSER_BEGIN(XMLSyntax)
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

package org.netbeans.modules.xml.text.syntax.javacc;

import java.io.*;
import org.netbeans.modules.xml.text.syntax.javacc.lib.*;

/** This must be included for javacc joy. 
 *  We use just token manager.
 */
class XMLSyntax {

    public static void main (String args[]) throws Exception {
        System.err.println ("Use Lexer instead."); // NOI18N
    }

}

PARSER_END(XMLSyntax)

/** TokenManager is modified so it seamlessly cooperate with Syntax.
 */
TOKEN_MGR_DECLS:
{
    //!!! enter proper bridge
    public final class Bridge extends XMLSyntaxTokenManager implements JJSyntaxInterface, JJConstants {
        public Bridge() {
            super(null);
        }
    }

//~~~~~~~~~~~~~~~~~~~~~ TEXT BASED SHARING START ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    private transient String myimage = "";  //contais image of last scanned [partial] token // NOI18N
    private transient String lastImage = ""; // NOI18N
    private transient int id;
    
    private int lastValidState; //contains last correct state
                                //state may become incorect if EOB is returned
                                //due to buffer end e.g.
                                //(a) <! moves to IN_DECL
                                //(b) <!-- moves to IN_COMMENT
                                //if (a) is followed by EOB that
                                //token manager enters illegal state

    /** Return current state of lexan. 
     * There will be probably necessary simple ID mappe among
     * Syntax's state IDs with reserved INIT(-1) and JavaCC DEFAULT(variable often the highest one).
     */
    public final int getState() {
        return curLexState;
    }
    
    /** Return length of last recognized token. ?? SKIP*/
    public final int getLength() {
        return myimage.length();
    }
    
    /** Return last token. */
    public final String getImage() {
        return myimage.toString();
    }
    
    /** Set state info to folowing one. */
    public final void setStateInfo(int[] state) {
        int[] newstate = new int[state.length];
        System.arraycopy(state, 0, newstate, 0, state.length);
        states = newstate;
//          dumpStack("L"); // NOI18N
        lastValidState = popState(); //restore lastValidState
    }

    /** return copy of current state. */
    public final int[] getStateInfo() {
        pushState(lastValidState); // store lastValidState  !modifies states stack
        int[] state = new int[states.length];
        System.arraycopy(states, 0, state, 0, states.length);
//          dumpStack("S"); // NOI18N
        popState();                // !restore the states stack
        return state;
    }


    private void dumpStack(String label) {
        StringBuffer s = new StringBuffer();
        s.append(label + " "); // NOI18N
        for (int i = 0; i<states.length; i++) {
            s.append(states[i] + ", "); // NOI18N
        }
        System.err.println(s.toString());
    }
    
    /** Set input stream to folowing one
     *  and reset initial state.
     */
    public final void init(CharStream input) {
        ReInit((UCode_CharStream)input);
        lastValidState = getState();
    }
    
    /** Set input stream to folowing one
     *  and set current state.
     */
    public final void init(CharStream in, int state) {    
        ReInit((UCode_CharStream)in, state);
        lastValidState = getState();
    }
    
    /** Syntax would want restore state on buffer boundaries. */
    public final void setState(int state) {
        lastValidState = state;
        SwitchTo(state == -1 ? defaultLexState : state); //fix deleting at document start
    }
    
    //
    // push analyzer state to states stack
    //
    private void pushState(int state) {
        if (states == null) {
            states = new int[] {state};
        } else {
            int[] newstates = new int[states.length + 1];
            System.arraycopy(states, 0, newstates, 0, states.length);
            newstates[newstates.length - 1] = state;
            states = newstates;    
        }
    }

    //
    // pop analyzer state from states stack
    //
    private int popState() {
        int state = states[states.length - 1];
        if (states.length == 1) {
            states = null;
        } else {
            int[] newstates = new int[states.length - 1];
            System.arraycopy(states, 0, newstates, 0, states.length - 1);
            states = newstates;
        }
        return state;
    }

    /** Prepare next token from stream. */
    public final void next() {
        try {
            Token tok = getNextToken();
            myimage = tok.image;
            id = tok.kind;
            if (id == EOF) { //??? EOF is visible just at Parser LEVEL
                setState(lastValidState);
                id = Bridge.JJ_EOF;
            }
            lastValidState = getState();

        } catch (TokenMgrError ex) {  
            try {  
                //is the exception caused by EOF?
                char ch = input_stream.readChar();
                input_stream.backup(1);

                myimage = input_stream.GetImage();
                if (Boolean.getBoolean("netbeans.debug.exceptions")) // NOI18N
                    System.err.println(getClass().toString() + " ERROR:" + getState() + ":'" + ch + "'");
                id = Bridge.JJ_ERR;      

            } catch (IOException eof) {           

                myimage = input_stream.GetImage();          
                id = Bridge.JJ_EOF;
            }
        }    
    }

    /** Return ID of the last recognized token. */
    public int getID() {
        return id;
    }

    /** Return name of the last token. */
    public final String getName() {
        return tokenImage[id];
    }

    /** For testing purposes only. */
    public static void main(String args[]) throws Exception {

        InputStream in;
        int dump = 0;
        int dump2 = 1000;

        System.err.println("Got " + args.length + " arguments.");

        if (args.length != 0) {
            in = new FileInputStream(args[0]);
            if (args.length == 2) { //dump just requested line
                dump = Integer.parseInt(args[1]) - 1;
                dump2 = dump;
                System.err.println("Line to be dumped:" + dump);
            }
        } else  {
            System.err.println("One argument required.");
            return;
        }

        CharStream input = new ASCIICharStream(in, 0, 0);
        Bridge lex = null; //new XMLSyntaxTokenManager(input);

        int i = 25; //token count
        int id;
        int toks = 0;
        long time = System.currentTimeMillis();

        while (i/*--*/>0) {

            lex.next();
            id = lex.getID();

            toks++;
            switch (id) {
            case Bridge.JJ_EOF:
                System.err.println("EOF at " + lex.getState() + " " + lex.getImage());
                System.err.println("Line: " + input.getLine() );
                System.err.println("Tokens: " + toks );
                System.err.println("Time: " + (System.currentTimeMillis() - time) );
                return;

            default:
                if (dump <= input.getLine() && input.getLine() <= dump2)
                    System.err.println(" " + id + "@" + lex.getState() + ":" + lex.getImage() );
            }

        }

    }

    /**
     * The analyzer may store information about state in this
     * stack (array). These will be used as Syntax state info.
     */
    private int[] states = null;
}




/*##########################################################*/
/*              LEXAN                                       */
/*#########################################################3*/

/** Syntax requires recognition of newlines in any context. */
<*>
TOKEN: 
{
/** global text matches all but following chars.
 * ("<" | ">" | "'" | "\"" | "&" | "%"| ";" | "[" | "]" | "=" | "/" | "!" | "?" | "#")+
 */
  <#TEXT: (~[" ", "\t", "\n", "<", ">", "'", "\"", "&", "%", ";", "[", "]" , "=" , "/" , "!" , "?", "#"])>  
|
  <#CONTENT: (~["\n","<",">","&"])>
| /** global white space. */
  <#WS: (" " | "\t" | "\n" | "\r")>  
| //[3]
  <#S: (" " | "\t" | "\n" | "\r")+ >  
|
  <#NAME: (~[" ", "\t", "\n", "<", ">", "'", "\"", "&", "%", ";", "[", "]" , "=" , "/" , "!" , "?", "#"])+>
}

/** 
 * Initial state could be a switch allowing then guess 
 * which token is just recognized.
 *
 */
<DEFAULT> //COMMENT //GREF
TOKEN:
{
//  <RCB: ">"> //doctype end? -symbol
  <RSB: "]"> //dctype end? - symbol
| <TAG_START: "<"> : IN_TAG
| <DECL_START: "<!"> : IN_DECL
| <PI_START: "<?"> : IN_PI
| <CDATA_START: "<![CDATA["> : IN_CDATA
| <COND_END_IN_DEFAULT: "]]>"> //little bit tricky - what it would be else?
| <DTD_END_IN_DEFAULT: "]>">
| <TEXT_IN_DEFAULT: (~["<", "]", "&"])+ | ">" | "]">
| <ERR_IN_DEFAULT: "<<">
}

/** < ... > */
<IN_TAG>
TOKEN:
{
  <TAG_NAME: (("/")? <NAME>) > : IN_TAG_ATTLIST     //                         ?
| <ERR_IN_TAG: ("<" | "'" | "\"" | "&" | "%"| ";" | "[" | "]" | "=" | "!" | " " | ">")+ | "/">  //?!
}

/** pairs <tag ... >*/
<IN_TAG_ATTLIST>  //GREFSTRING //GREFCHARS
TOKEN:
{
  <ATT_NAME: (<NAME>)>  //                                        ?     ?
| <ERR_IN_TAG_ATTLIST: ("<" | "&" | "%"| ";" | "[" | "]" | "!" | "/" | "?")+ >
| <WS_IN_TAG_ATTLIST: (<WS>)+>
| <EQ_IN_TAG_ATTLIST: "=">
| <TAG_END: ("/")? ">"  > : DEFAULT
}



/** <? ... ?> */
<IN_PI>
TOKEN:
{
  <XML_TARGET: "xml"> : IN_XML_DECL
| <PI_CONTENT_START: <S> > : IN_PI_CONTENT
| <PI_END: "?>"> : DEFAULT //be tolerant to missing <WS> <?pi?>
| <ERR_IN_PI: "XML" | ("<" | ">" | "'" | "\"" | "&" | "%"| ";" | "[" | "]" | "=" | "/" | "!" )+>
| <PI_TARGET: (<NAME>)>
}

/** <?pi ... ?> */
<IN_PI_CONTENT>
TOKEN:
{

  <PI_CONTENT_END: "?>"> : DEFAULT
| <TEXT_IN_PI_CONTENT: ((<TEXT>)+ | (<WS>)+ | ( "'" | "\"" | "#" | "?" | ">" | "&" | "%"| ";" | "[" | "]" | "=" | "/" | "!" )) >
| <ERR_IN_PI_CONTENT: ("<")+>   
}


/** <?xml ... ?>
*   just treat well known xml declaration "attributes" as keywords
*/
<IN_XML_DECL>
TOKEN:
{
  <KW_IN_XML_DECL: "version" | "encoding" | "standalone" >
| <TEXT_IN_XML_DECL: (~["\n", "\t", " ", "?", "="])+ >
| <BR_IN_XML_DECL: ("\t" | " " | "=" | "\n")+ >
| <XML_DECL_END: "?>" > : DEFAULT
| <Q_IN_XML_DECL: "?">
}


/** In CDATA if allowed any character except "]]>" */
<IN_CDATA>
TOKEN:
{
  <CDATA_END: "]]>"> : DEFAULT
| <TEXT_IN_CDATA: <CDATA_CONTENT> | "<">
| <MARKUP_IN_CDATA: "<" ("!" | "/")? <NAME> (<CDATA_CONTENT>)? ">">
| <#CDATA_CONTENT: ((~["]", "<"])+ | ("]" ~["]"])+ | ("]]" ~[">"])+)+ >
}

/** declaration is <! ... */
<IN_DECL>
TOKEN:
{
  <ENTITY: "ENTITY"> : IN_ENTITY_DECL
| <ATTLIST: "ATTLIST"> : IN_ATTLIST_DECL
| <DOCTYPE: "DOCTYPE"> : IN_DOCTYPE
| <ELEMENT: "ELEMENT"> : IN_ELEMENT
| <NOTATION: "NOTATION"> : IN_NOTATION
| <TEXT_IN_DECL: (<TEXT>)+ >
| <WS_IN_DECL: (<WS>)+ >
| <ERR_IN_DECL: ("<" | "'" | "\"" | ";" | "]" | "=" | "/" | "!")+>
| <COND: "["> : IN_COND
| <DECL_END: ">"> : DEFAULT  
}

<IN_ENTITY_DECL> //STRING //CHARS //PREF
TOKEN:
{
  <KW_IN_ENTITY: "SYSTEM" | "NDATA" | "PUBLIC">
| <TEXT_IN_ENTITY:  (<WS>)+ | (<TEXT> | "<" | "&" | ";" | "[" | "]" | "=" | "/" | "!")+>
| <ENTITY_END: ">" > : DEFAULT
}

<IN_ELEMENT> //PREF
TOKEN:
{
  <EMPTY: "EMPTY">
| <PCDATA: "#PCDATA">
| <ANY: "ANY">
| <TEXT_IN_ELEMENT: (<TEXT>)+ | (<WS>)+ | "?" > 
| <ELEMENT_END: ">"> : DEFAULT
}

/** 
 * [82]   NotationDecl ::= '<!NOTATION' S Name S (ExternalID | PublicID) S? '>'
 *                                     ^
 */
<IN_NOTATION> //CHARS //STRING  ??GREF
TOKEN:
{
  <SYSTEM_IN_NOTATION: "SYSTEM" | "PUBLIC">
| <TEXT_IN_NOTATION: (<TEXT> | "&"| "%" | ";" | "[" | "]" | "=" | "/" | "!" | "?" | "#")+ | (<WS>)+ >
| <ERR_IN_NOTATION: ("<")>
| <NOTATION_END: ">"> : DEFAULT
}

/** 
* Conditional section "<![ ... [" declatation. Content of the section 
* is treated by DEFAULT => the end delimiter too.
* This code only tries to colorize "INCLUDE", "IGNORE" as kw.
*/
<IN_COND> //PREF
TOKEN:
{
  <INCLUDE: "INCLUDE">
| <IGNORE: "IGNORE">
| <TEXT_IN_COND: (<WS>)+ >
| <ERR_IN_COND: ((<TEXT>)+ | ("<" | ">" | "'" | "\"" | "&" | ";" | "]" | "!" | "/")+) >
| <COND_END: "["> : DEFAULT
}

/** List of attribures */
<IN_ATTLIST_DECL> //STRING //CHARS
TOKEN:
{
  <ERR_IN_ATTLIST: ("<")+ >
| <REQUIRED: "#REQUIRED">
| <IMPLIED: "#IMPLIED">
| <FIXED: "#FIXED">
| <ID_IN_ATTLIST: "ID">
| <CDATA: "CDATA">
| <IDREF: "IDREF">
| <IDREFS: "IDREFS">
| <ENTITY_IN_ATTLIST: "ENTITY">
| <ENTITIES: "ENTITIES">
| <NMTOKEN: "NMTOKEN">
| <NMTOKENS: "NMTOKENS">
| <NOTATION_IN_ATTLIST: "NOTATION">
| <TEXT_IN_ATTLIST: ((<WS>)+ | (<TEXT>)+ | ("&" | "%" | ";" | "[" | "]")+)>
| <ATTLIST_END: ">"> : DEFAULT
}

/** 
* Doctype section "<!DOCTYPE ... [>" declatation. Content of the section 
* is treated by DEFAULT => the end delimiter too.
* This code only tries to colorize "SYSTEME", "PUBLIC" as kw.
*/
<IN_DOCTYPE> //PREF //STRING //CHARS
TOKEN:
{
  <PUBLIC: "PUBLIC">
| <SYSTEM: "SYSTEM">
| <TEXT_IN_DOCTYPE: (<WS>)+ | (<TEXT>)+ >
| <ERR_IN_DOCTYPE: ("<" | ";" | "]" | "!" | "=" | "/" | "&")+ >
| <DOCTYPE_END: "[" | ">"> : DEFAULT
}

/*########################################################*/
// reused automatons

/** REFERENCE is delimited by "%" | "&" ... ";" | <WS> 
  It could be optimized by introcusing just IN_REF state
  shared by GREF & PREF because they can not be nested.
*/
<IN_DOCTYPE, IN_ELEMENT, IN_COND, IN_ENTITY_DECL>
TOKEN:
{
  <PREF_START: "%"> { pushState(getState()); } : IN_PREF
}

<IN_PREF>
TOKEN:
{
  <TEXT_IN_PREF: (<TEXT>)+ > 
| <PREF_END: ";" | (<WS>)+ > { setState(popState()); }  //<WS> is just for error recovery
}

<DEFAULT, IN_GREF_CHARS, IN_GREF_STRING>
TOKEN:
{
  <GREF_START: "&"> { pushState(getState()); } : IN_GREF
}

<IN_GREF>
TOKEN:
{
  <TEXT_IN_GREF: (<TEXT> | "#")+ > 
| <ERR_IN_GREF: "/" | ">" | "<" | "&" | "'" | "\"" | "?" | "%" | "!"> { setState(popState()); } // error recovery
| <GREF_END: ";" | (<WS>)+ > { setState(popState()); }
}


// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

/** 
 * CHARS automaton delimited by "'" 
 */
<IN_ENTITY_DECL, IN_ATTLIST_DECL, IN_DOCTYPE, IN_NOTATION>
TOKEN:
{
  <CHARS_START: "'"> { pushState(getState()); } : IN_CHARS
}

<IN_CHARS>
TOKEN:
{
  <TEXT_IN_CHARS: (~["'"])+>
| <CHARS_END: "'"> { setState(popState()); }
}


/** 
 * GREF_CHARS automaton delimited by "'" allowing &subs;
 */
<IN_TAG_ATTLIST>
TOKEN:
{
  <GREF_CHARS_START: "'"> { pushState(getState()); } : IN_GREF_CHARS
}

<IN_GREF_CHARS>
TOKEN:
{
  <TEXT_IN_GREF_CHARS: (~["'", "&"])+>
| <GREF_CHARS_END: "'"> { setState(popState()); }
}


/** 
 * STRING automaton delimited by "\"" 
 */
<IN_ENTITY_DECL, IN_ATTLIST_DECL, IN_DOCTYPE, IN_NOTATION>
TOKEN:
{
  <STRING_START: "\""> { pushState(getState()); } : IN_STRING
}

<IN_STRING>
TOKEN:
{
  <TEXT_IN_STRING: ((~["\""])+)>
| <STRING_END: "\""> { setState(popState()); }

}

/** 
 * GREF_STRING automaton delimited by "\"" 
 */
<IN_TAG_ATTLIST>
TOKEN:
{
  <GREF_STRING_START: "\""> { pushState(getState()); } : IN_GREF_STRING
}

<IN_GREF_STRING>
TOKEN:
{
  <TEXT_IN_GREF_STRING: ((~["\"", "&"])+)>
| <GREF_STRING_END: "\""> { setState(popState()); }

}

// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

/** 
 * COMMENT automaton delimited by "-->" 
 */
<DEFAULT>
TOKEN:
{
  <COMMENT_START: "<!--"> { pushState(getState()); } : IN_COMMENT
}

<IN_COMMENT>
/* Comment is delimited by multiple character delimiter.
   The comment end regular expressions must throw TokenMgrError 
   to indicate that the lexer is in the middle of token at
   buffer boundaries!
*/
TOKEN:
{
  <TEXT_IN_COMMENT: ( (~["-"])+ | ("-" ~["-"])+ )+  >
| <ERR_IN_COMMENT: "--" ~[">"] > 
| <COMMENT_END: "-->" > { setState(popState()); }
}
